{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IF240 - Machine learning and deep learning\n",
    "\n",
    "## TP 2 - Naive Bayes classifier and evaluation metrics\n",
    "\n",
    "By AurÃ©lie Bugeau and MichaÃ«l ClÃ©ment \n",
    "\n",
    "Credits: Vincent Lepetit, Varun Kumar, Mohit Deshpande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives \n",
    "The objective of the practice is to classifiy emails from a dataset as *spam* or *ham* (non-spam).\n",
    "\n",
    "You will implement the Naive Bayes classifier, and test the model with several evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "### Presentation and Loading\n",
    "\n",
    "The dataset used here contained 747 *spam* and 4825 *ham* emails. \n",
    "Emails in the corpus have been already pre-processed in the following ways:\n",
    "\n",
    "- Removal of stop words (and, the, of, etc)\n",
    "- Lemmatization (variations of words such as *inludes*, *included*, *include* are now all considered as *include*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     4825\n",
      "spam     747\n",
      "Name: Category, dtype: int64\n",
      "  Category                                            Message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro... \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Open the dataset and count the number of spam/ham mails\n",
    "mails = pd.read_csv(\"spamham.csv\")\n",
    "count = mails['Category'].value_counts()\n",
    "print(count)\n",
    "print(mails.head(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation sets\n",
    "Split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data as training and testing sets\n",
    "mask = np.random.rand(len(mails)) < 0.8\n",
    "training_set = mails[mask]\n",
    "testing_set = mails[~mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take some time to study how to access the messages and categories for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Go until jurong point, crazy.. Available only ...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "5       FreeMsg Hey there darling it's been 3 week's n...\n",
      "                              ...                        \n",
      "5565                                         Huh y lei...\n",
      "5566    REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Message, Length: 4388, dtype: object\n",
      "ham     3795\n",
      "spam     593\n",
      "Name: Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# COMPLETE\n",
    "X_train = training_set['Message']\n",
    "y_train = training_set['Category']\n",
    "X_test = testing_set['Message']\n",
    "y_test = testing_set['Category']\n",
    "print(X_train)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Classification\n",
    "\n",
    "The classifier must be able to predict the label based on the text by implementing the following pseudo code, based on the bayesian decision rule:\n",
    "\n",
    "`if (P(ham | message) > P(spam | message)) return ham else return spam`\n",
    "\n",
    "where\n",
    "\\begin{align}\n",
    "P(\\text{ham} \\,|\\, message)  &= \\text{Probability that the message is ham given its observed features} \\\\\n",
    "P(\\text{spam} \\,|\\, message) &= \\text{Probability that the message is spam given its observed features}\n",
    "\\end{align}\n",
    "\n",
    "The features will be based on the number of occurence of each word in the message.\n",
    "\n",
    "(See the bag-of-words model: https://en.wikipedia.org/wiki/Bag-of-words_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "\n",
    "Apply the Naive Bayes formula in the following code to implement a classifier. With the naive assumption, we will consider that:\n",
    "\n",
    "$$P(\\text{message} \\,|\\, \\text{spam}) = \\prod_i P(w_i \\,|\\, \\text{spam}) $$\n",
    "where $w_i$ is the frequency of word $i$ in the message.\n",
    " \n",
    "*Note:* if the vocabulary is large and if some words are very rare, we may encounter problems as $P(w_i\\,|\\,\\text{ham})$ or $P(w_i\\,|\\,\\text{spam})$ can be close to 0 for some $w_i$, therefore driving the product towards 0. This can also lead to numerical issues when the resulting probabilities are very small.\n",
    "To solve this problem, it is convenient to apply $\\log$ on both sides. We then have:\n",
    "\n",
    "$$log(P(\\text{message} \\,|\\, \\text{spam})) = \\sum_i log(P(w_i \\,|\\, \\text{spam})) $$\n",
    "\n",
    "But the problem is still not completely solved. If the classifier encounters a new word that is not present in a given category of our training set, or in the test set, then $P(w_i | \\text{category})$ will be 0 and $log(0)$ is undefined. To solve this problem, we can use the so-called Laplace smoothing technique:\n",
    "\n",
    "$$P(w_1 \\,|\\, \\text{spam}) = \\frac{\\text{#occurrences of } w_i \\text{ in spam} + 1}{\\text{#words in spam}+ \\text{#distinct words in training set}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for detecting spam using Naive Bayes\n",
    "class SpamDetectorNB(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.log_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.word_index = {}\n",
    "        self.vocab = set()\n",
    "    \n",
    "    # Compute log class priors log(ð‘ƒ(â„Žð‘Žð‘š)) and log(ð‘ƒ(spð‘Žð‘š))  \n",
    "    # by counting up how many spam/ham messages are in our dataset and dividing by the total number\n",
    "    def compute_log_priors(self, X_train, y_train):\n",
    "        # COMPLETE\n",
    "        total_size = len(y_train)\n",
    "        ham_size = y_train.value_counts()[0]\n",
    "        spam_size = total_size - ham_size\n",
    "        self.log_priors['spam'] = math.log(spam_size/total_size)\n",
    "        self.log_priors['ham'] = math.log(ham_size/total_size)\n",
    "    \n",
    "    # Tokenize a string into words    \n",
    "    def tokenize(self, text):\n",
    "        return re.split(\"\\W+\", text)\n",
    "\n",
    "    # Count how many times each word appears in a text. \n",
    "    # Returns a dictionary that contains for each word the number of times it appears in text. \n",
    "    def get_word_counts(self, text):\n",
    "        text_tokenized = self.tokenize(text)\n",
    "        word_counts = {i: text.count(i) for i in text_tokenized}\n",
    "        return word_counts\n",
    "    \n",
    "    # Create a dictionary (a vocabulary of words)\n",
    "    # and count words frequency for spam and ham separately\n",
    "    def compute_word_frequencies(self, X_train, y_train):\n",
    "        self.word_counts['spam'] = {}\n",
    "        self.word_counts['ham'] = {}\n",
    "        for text, label in zip(X_train, y_train):\n",
    "            counts = self.get_word_counts(text)\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.word_index[word] = len(self.vocab)\n",
    "                    self.vocab.add(word)\n",
    "                if word not in self.word_counts[label]:\n",
    "                    self.word_counts[label][word] = 0.0\n",
    "                self.word_counts[label][word] += count\n",
    "                \n",
    "                \n",
    "    # Compute all necessary features\n",
    "    def train(self, X_train, y_train):\n",
    "        self.compute_log_priors(X_train, y_train)\n",
    "        self.compute_word_frequencies(X_train, y_train)\n",
    "        \n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        predictions = []\n",
    "        for text in X_test:\n",
    "            # Compute word counts\n",
    "            counts = self.get_word_counts(text)\n",
    "            # Initialize log posteriors ð‘™ð‘œð‘”(ð‘ƒ(spam|message)) and ð‘™ð‘œð‘”(ð‘ƒ(ham|message)) according to log priors\n",
    "            # COMPLETE\n",
    "            log_P_spam_message = self.log_priors['spam']\n",
    "            log_P_ham_message = self.log_priors['ham']\n",
    "            # Update log posteriors with log likelihoods of each word\n",
    "            for word, count in counts.items():     \n",
    "                # Compute log likelihoods log(P(w|spam)) and log(P(w|ham))\n",
    "                # COMPLETE\n",
    "                log_word_spam = math.log(self.word_counts['spam'].get(word,0)+1)-math.log((len(self.word_counts['spam']) + len(self.vocab)))\n",
    "                log_word_ham = math.log(self.word_counts['ham'].get(word,0)+1)-math.log((len(self.word_counts['ham']) + len(self.vocab)))\n",
    "                # Update log posteriors\n",
    "                # COMPLETE\n",
    "                log_P_spam_message += log_word_spam\n",
    "                log_P_ham_message += log_word_ham                \n",
    "            # Apply the bayesian decision rule to classify spam or ham\n",
    "            # COMPLETE\n",
    "            if(log_P_spam_message < log_P_ham_message):\n",
    "                predictions.append('ham')\n",
    "            else:\n",
    "                 predictions.append('spam')\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham']\n"
     ]
    }
   ],
   "source": [
    "# Apply the classifier to the spam dataset\n",
    "sd = SpamDetectorNB()\n",
    "sd.train(X_train, y_train)\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "result = sd.predict(X_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 - Evaluation metrics and confusion matrix\n",
    "Compute the precision, recall, accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9921\n",
      "Recall: 0.8182\n",
      "Accuracy : 0.9755\n",
      "Confusion matrix using SpamDetectorNB:\n",
      "              Present   Not present\n",
      "Detected       126          1\n",
      "Not detected   28          1029\n"
     ]
    }
   ],
   "source": [
    "def numbers():\n",
    "    nb_tp = 0\n",
    "    nb_fp = 0\n",
    "    nb_fn = 0\n",
    "    nb_tn = 0\n",
    "    for i,j in zip(y_test,result):\n",
    "        if(i == \"spam\" and j == \"spam\"):\n",
    "            nb_tp+=1\n",
    "        elif(i == \"ham\" and j == \"spam\"):\n",
    "            nb_fp+=1\n",
    "        elif(i == \"spam\" and j == \"ham\"):\n",
    "            nb_fn+=1\n",
    "        elif(i == \"ham\" and j == \"ham\"):\n",
    "            nb_tn+=1\n",
    "    return nb_tp, nb_fp,nb_fn,nb_tn\n",
    "\n",
    "nb_tp,nb_fp,nb_fn,nb_tn = numbers()\n",
    "\n",
    "precision = nb_tp/(nb_tp+nb_fp)\n",
    "\n",
    "recall = nb_tp/(nb_tp+nb_fn)\n",
    "\n",
    "accuracy = (nb_tp+nb_tn)/(nb_tp+nb_fp+nb_fn+nb_tn)\n",
    "\n",
    "# COMPLETE\n",
    "print(\"Precision: {0:.4f}\".format(precision))\n",
    "print(\"Recall: {0:.4f}\".format(recall))\n",
    "print(\"Accuracy : {0:.4f}\".format(accuracy))\n",
    "print(\"Confusion matrix using SpamDetectorNB:\")\n",
    "print(\"              Present   Not present\")\n",
    "print(\"Detected      \",nb_tp,\"        \", nb_fp)\n",
    "print(\"Not detected  \",nb_fn,\"        \", nb_tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 - Naive Bayes with Scikit-learn library\n",
    "The `scikit-learn` library proposes many functions for machine learning.  Study the documentation of the  `MultinomialNB` class and apply it for spam detection.\n",
    "\n",
    "You will need to convert the dataset into arrays and to normalize the word counts into frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#converting the dataset into arrays \n",
    "vectorizer = CountVectorizer()\n",
    "features = vectorizer.fit_transform(mails['Message']).toarray()\n",
    "\n",
    "#creating labelEncoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "mails_encoded=le.fit_transform(mails['Category'])\n",
    "\n",
    "# split train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, mails_encoded, random_state=0)\n",
    "\n",
    "#Creating naive bayes classifier \n",
    "model = MultinomialNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Predict Output\n",
    "y_predicted= model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 - Evaluation with Scikit-learn library\n",
    "\n",
    "The `scikit-learn` library also proposes  functions to evaluate machine learning methods.\n",
    "\n",
    "Apply them to the spam detection problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9806\n",
      "Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.99      0.99      1208\n",
      "        spam       0.92      0.93      0.93       185\n",
      "\n",
      "    accuracy                           0.98      1393\n",
      "   macro avg       0.96      0.96      0.96      1393\n",
      "weighted avg       0.98      0.98      0.98      1393\n",
      "\n",
      "Confusion matrix using MultinomialNB:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "#visualisation of the accuracy\n",
    "accuracy = accuracy_score(y_test, y_predicted)\n",
    "print(\"accuracy: {0:.4f}\".format(accuracy))\n",
    "\n",
    "#visualisation of the classification report\n",
    "print(\"Report:\")\n",
    "print(metrics.classification_report(y_test, y_predicted,target_names=mails['Category'].unique()))\n",
    "\n",
    "#visualisation of the confusion matrix\n",
    "print(\"Confusion matrix using MultinomialNB:\")\n",
    "matrix = confusion_matrix(y_test, y_predicted)\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "sns.heatmap(matrix, square=True, annot=True, fmt='d', cbar=False\\\n",
    "            , xticklabels = ['ham', 'spam'],yticklabels = ['ham', 'spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
